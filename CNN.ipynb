{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_loader import ImagesLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dataset = ImagesLoader()\n",
    "\n",
    "train_split = 0.2\n",
    "validation_split = 0.1\n",
    "batch_size = 12\n",
    "\n",
    "data_size = len(dataset)\n",
    "print(f'dataset contains {data_size} Images')\n",
    "\n",
    "train_size = int(train_split * data_size)\n",
    "val_size = int(validation_split * data_size)\n",
    "test_size = data_size - (val_size + train_size)\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_samples = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_samples = DataLoader(val_data, batch_size=batch_size)\n",
    "test_samples = DataLoader(test_data, batch_size=batch_size)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = models.resnet50(pretrained=True).to(device)\n",
    "        for i, param in enumerate(self.features.parameters()):\n",
    "            if i < 47:\n",
    "                param.requires_grad=False\n",
    "            else:\n",
    "                param.requires_grad=True\n",
    "        self.features.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024), # first arg is the size of the flattened output from resnet50\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 13)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # x = torch.nn.Linear(256, 13),\n",
    "        # x = torch.nn.Softmax(dim=1)\n",
    "        # predict = self.fc(x)\n",
    "        # fully_connected = x\n",
    "        # print(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "#%%\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    writer = SummaryWriter()\n",
    "    model.train()\n",
    "    optimiser = optim.SGD(model.parameters(), lr=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (features, labels) in enumerate(train_samples):\n",
    "        # [train_samples, val_samples]:\n",
    "        #     if batch == train_samples:\n",
    "        #         model.train()\n",
    "        #     else:\n",
    "        #         model.eval()\n",
    "\n",
    "            predict = model(features)\n",
    "            loss = F.cross_entropy(predict, labels)\n",
    "            # if epoch == train_samples:\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            writer.add_scalar('Loss', loss, i)\n",
    "            writer.flush()\n",
    "            if i % 100 == 99:   \n",
    "                # print(batch) # print every 50 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss}')\n",
    "            \n",
    "\n",
    "train_model(model, 5)\n",
    "\n",
    "\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader == train_samples:\n",
    "        model.train()\n",
    "        print('Checking accuracy on training set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "        model.val()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    #   tells model not to compute gradients\n",
    "    with torch.no_grad():\n",
    "        for feature, label in loader:\n",
    "            feature = feature.to(device)  # move to device\n",
    "            label = label.to(device)\n",
    "            scores = model(feature)\n",
    "            # print(scores.max(1))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == label).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy: {acc}')\n",
    "\n",
    "\n",
    "\n",
    "check_accuracy(train_samples, model)\n",
    "check_accuracy(test_samples, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e510884cfc2d161432d212cfd768f3de9a805e4599418f66cff32f16447a06c3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
